{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>token_tag</th>\n",
       "      <th>token_dep</th>\n",
       "      <th>token_shape</th>\n",
       "      <th>token_is_alpha</th>\n",
       "      <th>token_is_stop</th>\n",
       "      <th>NER_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>nummod</td>\n",
       "      <td>d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>B-QUANTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>slice</td>\n",
       "      <td>slice</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>B-UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>whole</td>\n",
       "      <td>whole</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>B-ING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I-ING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>bread</td>\n",
       "      <td>bread</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I-ING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397955</th>\n",
       "      <td>181969</td>\n",
       "      <td>cut</td>\n",
       "      <td>cut</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>B-STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397956</th>\n",
       "      <td>181969</td>\n",
       "      <td>into</td>\n",
       "      <td>into</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>I-STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397957</th>\n",
       "      <td>181969</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>nummod</td>\n",
       "      <td>d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I-STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397958</th>\n",
       "      <td>181969</td>\n",
       "      <td>inch</td>\n",
       "      <td>inch</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I-STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397959</th>\n",
       "      <td>181969</td>\n",
       "      <td>chunks</td>\n",
       "      <td>chunk</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>I-STATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1397960 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sent_id token_text token_lemma token_pos token_tag token_dep  \\\n",
       "0              0          1           1       NUM        CD    nummod   \n",
       "1              0      slice       slice      NOUN        NN      nmod   \n",
       "2              0      whole       whole       ADJ        JJ      amod   \n",
       "3              0      wheat       wheat      NOUN        NN  compound   \n",
       "4              0      bread       bread      NOUN        NN      ROOT   \n",
       "...          ...        ...         ...       ...       ...       ...   \n",
       "1397955   181969        cut         cut      VERB       VBD      ROOT   \n",
       "1397956   181969       into        into       ADP        IN      prep   \n",
       "1397957   181969          2           2       NUM        CD    nummod   \n",
       "1397958   181969       inch        inch      NOUN        NN  compound   \n",
       "1397959   181969     chunks       chunk      NOUN       NNS      pobj   \n",
       "\n",
       "        token_shape  token_is_alpha  token_is_stop    NER_tags  \n",
       "0                 d           False          False  B-QUANTITY  \n",
       "1              xxxx            True          False      B-UNIT  \n",
       "2              xxxx            True           True       B-ING  \n",
       "3              xxxx            True          False       I-ING  \n",
       "4              xxxx            True          False       I-ING  \n",
       "...             ...             ...            ...         ...  \n",
       "1397955         xxx            True          False     B-STATE  \n",
       "1397956        xxxx            True           True     I-STATE  \n",
       "1397957           d           False          False     I-STATE  \n",
       "1397958        xxxx            True          False     I-STATE  \n",
       "1397959        xxxx            True          False     I-STATE  \n",
       "\n",
       "[1397960 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "temp = []\n",
    "tags = []\n",
    "temp_tags = []\n",
    "current_id = 0\n",
    "\n",
    "for item in df.itertuples(index=False):\n",
    "    if item.sent_id != current_id:\n",
    "        current_id += 1\n",
    "        sents.append(temp)\n",
    "        tags.append(temp_tags)\n",
    "        temp = []\n",
    "        temp_tags = []\n",
    "    temp.append(item)\n",
    "    temp_tags.append(item.NER_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Pandas(sent_id=0, token_text='1', token_lemma='1', token_pos='NUM', token_tag='CD', token_dep='nummod', token_shape='d', token_is_alpha=False, token_is_stop=False, NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=0, token_text='slice', token_lemma='slice', token_pos='NOUN', token_tag='NN', token_dep='nmod', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='B-UNIT'),\n",
       "  Pandas(sent_id=0, token_text='whole', token_lemma='whole', token_pos='ADJ', token_tag='JJ', token_dep='amod', token_shape='xxxx', token_is_alpha=True, token_is_stop=True, NER_tags='B-ING'),\n",
       "  Pandas(sent_id=0, token_text='wheat', token_lemma='wheat', token_pos='NOUN', token_tag='NN', token_dep='compound', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='I-ING'),\n",
       "  Pandas(sent_id=0, token_text='bread', token_lemma='bread', token_pos='NOUN', token_tag='NN', token_dep='ROOT', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='I-ING')],\n",
       " [Pandas(sent_id=1, token_text='0.5', token_lemma='0.5', token_pos='NUM', token_tag='CD', token_dep='meta', token_shape='d.d', token_is_alpha=False, token_is_stop=False, NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=1, token_text='(', token_lemma='(', token_pos='PUNCT', token_tag='-LRB-', token_dep='punct', token_shape='(', token_is_alpha=False, token_is_stop=False, NER_tags='O'),\n",
       "  Pandas(sent_id=1, token_text='1', token_lemma='1', token_pos='NUM', token_tag='CD', token_dep='nummod', token_shape='d', token_is_alpha=False, token_is_stop=False, NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=1, token_text='ounce', token_lemma='ounce', token_pos='NOUN', token_tag='NN', token_dep='npadvmod', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='B-UNIT'),\n",
       "  Pandas(sent_id=1, token_text=')', token_lemma=')', token_pos='PUNCT', token_tag='-RRB-', token_dep='punct', token_shape=')', token_is_alpha=False, token_is_stop=False, NER_tags='O'),\n",
       "  Pandas(sent_id=1, token_text='package', token_lemma='package', token_pos='NOUN', token_tag='NN', token_dep='nmod', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='B-UNIT'),\n",
       "  Pandas(sent_id=1, token_text='dry', token_lemma='dry', token_pos='ADJ', token_tag='JJ', token_dep='amod', token_shape='xxx', token_is_alpha=True, token_is_stop=False, NER_tags='B-ING'),\n",
       "  Pandas(sent_id=1, token_text='ranch', token_lemma='ranch', token_pos='NOUN', token_tag='NN', token_dep='compound', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='I-ING'),\n",
       "  Pandas(sent_id=1, token_text='-', token_lemma='-', token_pos='PUNCT', token_tag='HYPH', token_dep='punct', token_shape='-', token_is_alpha=False, token_is_stop=False, NER_tags='I-ING'),\n",
       "  Pandas(sent_id=1, token_text='style', token_lemma='style', token_pos='NOUN', token_tag='NN', token_dep='compound', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='I-ING'),\n",
       "  Pandas(sent_id=1, token_text='dressing', token_lemma='dressing', token_pos='NOUN', token_tag='NN', token_dep='amod', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='I-ING'),\n",
       "  Pandas(sent_id=1, token_text='mix', token_lemma='mix', token_pos='NOUN', token_tag='NN', token_dep='ROOT', token_shape='xxx', token_is_alpha=True, token_is_stop=False, NER_tags='I-ING')],\n",
       " [Pandas(sent_id=2, token_text='1', token_lemma='1', token_pos='NUM', token_tag='CD', token_dep='compound', token_shape='d', token_is_alpha=False, token_is_stop=False, NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=2, token_text='3/4', token_lemma='3/4', token_pos='NUM', token_tag='CD', token_dep='nummod', token_shape='d/d', token_is_alpha=False, token_is_stop=False, NER_tags='I-QUANTITY'),\n",
       "  Pandas(sent_id=2, token_text='liters', token_lemma='liter', token_pos='NOUN', token_tag='NNS', token_dep='npadvmod', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='B-UNIT'),\n",
       "  Pandas(sent_id=2, token_text='vodka', token_lemma='vodka', token_pos='NOUN', token_tag='NN', token_dep='ROOT', token_shape='xxxx', token_is_alpha=True, token_is_stop=False, NER_tags='B-ING')]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "andas(sent_id=0, token_text='1', token_lemma='1', token_pos='NUM', token_tag='CD', token_dep='nummod', token_shape='d', token_is_alpha=False, token_is_stop=False, NER_tags='B-QUANTITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is a sentence as a structure show above \n",
    "#and and ith word from the sentence to return the features for that word\n",
    "\n",
    "# Sample training data (replace with your actual data)\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = str(sent[i].token_text)\n",
    "    postag = sent[i].token_tag\n",
    "    \n",
    "    # data structure consisting of a feature name and value for the token\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(), # lower case variant of the token\n",
    "        'word[-3:]': word[-3:], #suffix of 3 characters\n",
    "        'word[-2:]': word[-2:], #suffix of 2 characters\n",
    "        'word.isupper()': word.isupper(), # initial captial\n",
    "        'word.istitle()': word.istitle(), # all words ini caps\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2], #first two characters of the PoS Tag\n",
    "    }\n",
    "    if i > 0:\n",
    "        # adding features for the word based on the previous word\n",
    "        word1 = str(sent[i-1].token_text) # previous word\n",
    "        postag1 = sent[i-1].token_tag\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True # Beginning of sentence as a feature\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        # adding features for the word based on the next word\n",
    "        word1 = str(sent[i+1].token_text) # next word\n",
    "        postag1 = sent[i+1].token_tag\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True # end of sentence as a feature\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [x.NER_tags for x in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in sents[:144000]]\n",
    "y_train = [sent2labels(s) for s in sents[:144000]]\n",
    "\n",
    "X_test = [sent2features(s) for s in sents[144000:]]\n",
    "y_test = [sent2labels(s) for s in sents[144000:]]\n",
    "\n",
    "# X_train = [sent2features(s) for s in sents[:1000]]\n",
    "# y_train = [sent2labels(s) for s in sents[:1000]]\n",
    "\n",
    "# X_test = [sent2features(s) for s in sents[1000:]]\n",
    "# y_test = [sent2labels(s) for s in sents[1000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-QUANTITY', 'B-UNIT', 'B-ING', 'I-ING', 'I-ING']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "# different parameters are used for training\n",
    "# check https://sklearn-crfsuite.readthedocs.io/en/latest/api.html?highlight=CRF\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1, #The coefficient for L1 regularization.\n",
    "          c2=0.1, #The coefficient for L2 regularization.\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('crf_big.pkl', 'wb') as f:\n",
    "    pickle.dump(crf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "pred = crf.predict(X_test)\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ING       0.97      0.97      0.97     43741\n",
      "   B-PRODUCT       0.95      0.96      0.95      3581\n",
      "  B-QUANTITY       1.00      1.00      1.00     43778\n",
      "     B-STATE       0.97      0.96      0.97     28151\n",
      "      B-UNIT       1.00      1.00      1.00     36395\n",
      "       I-ING       0.96      0.97      0.96     50024\n",
      "   I-PRODUCT       0.93      0.96      0.94     11549\n",
      "  I-QUANTITY       0.99      0.99      0.99       359\n",
      "     I-STATE       0.95      0.96      0.96     27016\n",
      "      I-UNIT       1.00      1.00      1.00       503\n",
      "           O       0.95      0.93      0.94     45346\n",
      "\n",
      "    accuracy                           0.97    290443\n",
      "   macro avg       0.97      0.97      0.97    290443\n",
      "weighted avg       0.97      0.97      0.97    290443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'I-ING': 190411,\n",
       "         'O': 174954,\n",
       "         'B-ING': 166340,\n",
       "         'B-QUANTITY': 166088,\n",
       "         'B-UNIT': 138598,\n",
       "         'B-STATE': 107162,\n",
       "         'I-STATE': 103138,\n",
       "         'I-PRODUCT': 43663,\n",
       "         'B-PRODUCT': 13744,\n",
       "         'I-UNIT': 1850,\n",
       "         'I-QUANTITY': 1560})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([x.NER_tags for y in sents[:144000] for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2featuresmod(sent, i):\n",
    "    word = sent[i].text\n",
    "    postag = sent[i].tag_\n",
    "    \n",
    "    # data structure consisting of a feature name and value for the token\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(), # lower case variant of the token\n",
    "        'word[-3:]': word[-3:], #suffix of 3 characters\n",
    "        'word[-2:]': word[-2:], #suffix of 2 characters\n",
    "        'word.isupper()': word.isupper(), # initial captial\n",
    "        'word.istitle()': word.istitle(), # all words ini caps\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2], #first two characters of the PoS Tag\n",
    "    }\n",
    "    if i > 0:\n",
    "        # adding features for the word based on the previous word\n",
    "        word1 = sent[i-1].text # previous word\n",
    "        postag1 = sent[i-1].tag_\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True # Beginning of sentence as a feature\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        # adding features for the word based on the next word\n",
    "        word1 = sent[i+1].text # next word\n",
    "        postag1 = sent[i+1].tag_\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True # end of sentence as a feature\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2featuresmod(sent):\n",
    "    return [word2featuresmod(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labelsmod(sent):\n",
    "    return [x.NER_tags for x in sent]\n",
    "\n",
    "def sent2tokensmod(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"6 ounces blue cheese,at room temperature\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "tokens = [token for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = sent2featuresmod(tokens)\n",
    "# prep\n",
    "\n",
    "predict = crf.predict([prep])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B-QUANTITY', 'B-UNIT', 'B-ING', 'I-ING', 'O', 'O', 'O', 'O']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_gk = pd.read_csv('ar_gk_train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_tag</th>\n",
       "      <th>NER_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CD</td>\n",
       "      <td>B-QUANTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cloves</td>\n",
       "      <td>clove</td>\n",
       "      <td>NNS</td>\n",
       "      <td>B-UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>garlic</td>\n",
       "      <td>garlic</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>CD</td>\n",
       "      <td>B-QUANTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tablespoons</td>\n",
       "      <td>tablespoon</td>\n",
       "      <td>NNS</td>\n",
       "      <td>B-UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37209</th>\n",
       "      <td>6609</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37210</th>\n",
       "      <td>6610</td>\n",
       "      <td>1Â 1/4</td>\n",
       "      <td>1Â 1/4</td>\n",
       "      <td>CD</td>\n",
       "      <td>B-QUANTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37211</th>\n",
       "      <td>6610</td>\n",
       "      <td>teaspoons</td>\n",
       "      <td>teaspoon</td>\n",
       "      <td>NNS</td>\n",
       "      <td>B-UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37212</th>\n",
       "      <td>6610</td>\n",
       "      <td>baking</td>\n",
       "      <td>baking</td>\n",
       "      <td>VBG</td>\n",
       "      <td>B-NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37213</th>\n",
       "      <td>6610</td>\n",
       "      <td>soda</td>\n",
       "      <td>soda</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NAME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37214 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sent_id   token_text token_lemma token_tag    NER_tags\n",
       "0            0            4           4        CD  B-QUANTITY\n",
       "1            0       cloves       clove       NNS      B-UNIT\n",
       "2            0       garlic      garlic        JJ      B-NAME\n",
       "3            1            2           2        CD  B-QUANTITY\n",
       "4            1  tablespoons  tablespoon       NNS      B-UNIT\n",
       "...        ...          ...         ...       ...         ...\n",
       "37209     6609        -RRB-       -RRB-        NN           O\n",
       "37210     6610        1Â 1/4       1Â 1/4        CD  B-QUANTITY\n",
       "37211     6610    teaspoons    teaspoon       NNS      B-UNIT\n",
       "37212     6610       baking      baking       VBG      B-NAME\n",
       "37213     6610         soda        soda        NN      I-NAME\n",
       "\n",
       "[37214 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ar_gk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "temp = []\n",
    "tags = []\n",
    "temp_tags = []\n",
    "current_id = 0\n",
    "\n",
    "for item in df_ar_gk.itertuples(index=False):\n",
    "    if item.sent_id != current_id:\n",
    "        current_id += 1\n",
    "        sents.append(temp)\n",
    "        tags.append(temp_tags)\n",
    "        temp = []\n",
    "        temp_tags = []\n",
    "    temp.append(item)\n",
    "    temp_tags.append(item.NER_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Pandas(sent_id=0, token_text='4', token_lemma='4', token_tag='CD', NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=0, token_text='cloves', token_lemma='clove', token_tag='NNS', NER_tags='B-UNIT'),\n",
       "  Pandas(sent_id=0, token_text='garlic', token_lemma='garlic', token_tag='JJ', NER_tags='B-NAME')],\n",
       " [Pandas(sent_id=1, token_text='2', token_lemma='2', token_tag='CD', NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=1, token_text='tablespoons', token_lemma='tablespoon', token_tag='NNS', NER_tags='B-UNIT'),\n",
       "  Pandas(sent_id=1, token_text='vegetable', token_lemma='vegetable', token_tag='JJ', NER_tags='B-NAME'),\n",
       "  Pandas(sent_id=1, token_text='oil', token_lemma='oil', token_tag='NN', NER_tags='I-NAME'),\n",
       "  Pandas(sent_id=1, token_text=',', token_lemma=',', token_tag=',', NER_tags='O'),\n",
       "  Pandas(sent_id=1, token_text='divided', token_lemma='divided', token_tag='VBD', NER_tags='B-STATE')]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in sents]\n",
    "y_train = [sent2labels(s) for s in sents]\n",
    "\n",
    "# X_test = [sent2features(s) for s in sents[144000:]]\n",
    "# y_test = [sent2labels(s) for s in sents[144000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "# different parameters are used for training\n",
    "# check https://sklearn-crfsuite.readthedocs.io/en/latest/api.html?highlight=CRF\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1, #The coefficient for L1 regularization.\n",
    "          c2=0.1, #The coefficient for L2 regularization.\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_gk_test = pd.read_csv('ar_gk_test_cleaned.csv')\n",
    "\n",
    "sents_test = []\n",
    "temp = []\n",
    "tags_test = []\n",
    "temp_tags = []\n",
    "current_id = 0\n",
    "\n",
    "for item in df_ar_gk_test.itertuples(index=False):\n",
    "    if item.sent_id != current_id:\n",
    "        current_id += 1\n",
    "        sents_test.append(temp)\n",
    "        tags_test.append(temp_tags)\n",
    "        temp = []\n",
    "        temp_tags = []\n",
    "    temp.append(item)\n",
    "    temp_tags.append(item.NER_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Pandas(sent_id=0, token_text='1/2', token_lemma='1/2', token_tag='CD', NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=0, token_text='large', token_lemma='large', token_tag='JJ', NER_tags='SIZE'),\n",
       "  Pandas(sent_id=0, token_text='sweet', token_lemma='sweet', token_tag='JJ', NER_tags='B-NAME'),\n",
       "  Pandas(sent_id=0, token_text='red', token_lemma='red', token_tag='JJ', NER_tags='I-NAME'),\n",
       "  Pandas(sent_id=0, token_text='onion', token_lemma='onion', token_tag='NN', NER_tags='I-NAME'),\n",
       "  Pandas(sent_id=0, token_text=',', token_lemma=',', token_tag=',', NER_tags='O'),\n",
       "  Pandas(sent_id=0, token_text='thinly', token_lemma='thinly', token_tag='RB', NER_tags='O'),\n",
       "  Pandas(sent_id=0, token_text='sliced', token_lemma='sliced', token_tag='VBD', NER_tags='B-STATE')],\n",
       " [Pandas(sent_id=1, token_text='6', token_lemma='6', token_tag='CD', NER_tags='B-QUANTITY'),\n",
       "  Pandas(sent_id=1, token_text='ounces', token_lemma='ounce', token_tag='NNS', NER_tags='B-UNIT'),\n",
       "  Pandas(sent_id=1, token_text='fresh', token_lemma='fresh', token_tag='JJ', NER_tags='DF'),\n",
       "  Pandas(sent_id=1, token_text='mushrooms', token_lemma='mushroom', token_tag='NNS', NER_tags='B-NAME'),\n",
       "  Pandas(sent_id=1, token_text=',', token_lemma=',', token_tag=',', NER_tags='O'),\n",
       "  Pandas(sent_id=1, token_text='sliced', token_lemma='sliced', token_tag='VBD', NER_tags='B-STATE')]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [sent2features(s) for s in sents_test]\n",
    "y_test = [sent2labels(s) for s in sents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME       0.91      0.93      0.92      2130\n",
      "  B-QUANTITY       0.98      0.99      0.99      2086\n",
      "     B-STATE       0.89      0.94      0.91       943\n",
      "      B-UNIT       0.97      0.97      0.97      1725\n",
      "          DF       0.96      0.96      0.96       196\n",
      "      I-NAME       0.89      0.90      0.89      1512\n",
      "  I-QUANTITY       0.95      0.86      0.90        65\n",
      "     I-STATE       0.81      0.68      0.74       150\n",
      "      I-UNIT       0.90      0.90      0.90        50\n",
      "           O       0.93      0.90      0.92      3655\n",
      "        SIZE       0.97      0.97      0.97       104\n",
      "        TEMP       0.84      0.84      0.84        43\n",
      "\n",
      "    accuracy                           0.93     12659\n",
      "   macro avg       0.92      0.90      0.91     12659\n",
      "weighted avg       0.93      0.93      0.93     12659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "pred = crf.predict(X_test)\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "       B-ING       0.86      0.87      0.86    208934\n",
    "   B-PRODUCT       0.76      0.59      0.66     17216\n",
    "  B-QUANTITY       0.99      1.00      1.00    208712\n",
    "     B-STATE       0.90      0.90      0.90    134547\n",
    "      B-UNIT       0.97      0.98      0.97    174033\n",
    "       I-ING       0.82      0.90      0.86    239159\n",
    "   I-PRODUCT       0.67      0.62      0.64     54871\n",
    "  I-QUANTITY       1.00      0.95      0.97      1906\n",
    "     I-STATE       0.89      0.88      0.89    129419\n",
    "      I-UNIT       1.00      0.99      1.00      2339\n",
    "           O       0.93      0.86      0.89    219008\n",
    "\n",
    "    accuracy                           0.90   1390144\n",
    "   macro avg       0.89      0.87      0.88   1390144\n",
    "weighted avg       0.90      0.90      0.90   1390144\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
