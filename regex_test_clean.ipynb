{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "regex = \"([0-9]*\\.?[0-9]*)(?: *)?(\\( ([0-9]*)(?: *)?([a-z]*) \\))?(?: *)?([a-z]*)(?: *)?(?:of )?(.*)\"\n",
    "\n",
    "test_regex = re.compile(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "gram = (\"NP: {<VB.*|JJ>?<N.*>*}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_INQ = pd.read_csv('df_INQ_test_cleaned.csv')\n",
    "df_ingredients = pd.read_csv('df_ingredients_clean.csv')\n",
    "\n",
    "df_INQ.drop(columns=['Unnamed: 0'], inplace= True)\n",
    "df_ingredients.drop(columns=['Unnamed: 0'], inplace= True)\n",
    "\n",
    "df_INQ_agged = df_INQ.groupby('ID', as_index=False).agg(pd.Series.tolist)\n",
    "df_ingredients_agged = df_ingredients.groupby('ID', as_index=False).agg(pd.Series.tolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "units = ['assortment',\n",
    " 'bag',\n",
    " 'bags',\n",
    " 'ball',\n",
    " 'balls',\n",
    " 'bar',\n",
    " 'bars',\n",
    " 'basket',\n",
    " 'baskets',\n",
    " 'batch',\n",
    " 'blades',\n",
    " 'block',\n",
    " 'bone',\n",
    " 'bottle',\n",
    " 'bottles',\n",
    " 'bowl',\n",
    " 'bowls',\n",
    " 'box',\n",
    " 'boxes',\n",
    " 'bulb',\n",
    " 'bulbs',\n",
    " 'bunch',\n",
    " 'bunches',\n",
    " 'can',\n",
    " 'canister',\n",
    " 'cans',\n",
    " 'carton',\n",
    " 'cartons',\n",
    " 'chunk',\n",
    " 'chunks',\n",
    " 'clove',\n",
    " 'cloves',\n",
    " 'container',\n",
    " 'containers',\n",
    " 'cube',\n",
    " 'cubes',\n",
    " 'cup',\n",
    " 'cups',\n",
    " 'dash',\n",
    " 'dashes',\n",
    " 'drop',\n",
    " 'drops',\n",
    " 'ear',\n",
    " 'ears',\n",
    " 'flatout',\n",
    " 'fluid ounces',\n",
    " 'foot',\n",
    " 'g',\n",
    " 'gallon',\n",
    " 'gallons',\n",
    " 'gram',\n",
    " 'grams',\n",
    " 'handful',\n",
    " 'head',\n",
    " 'heads',\n",
    " 'inch',\n",
    " 'inches',\n",
    " 'jar',\n",
    " 'jars',\n",
    " 'kg',\n",
    " 'knob',\n",
    " 'lb',\n",
    " 'leaf',\n",
    " 'leaves',\n",
    " 'length',\n",
    " 'lengths',\n",
    " 'liter',\n",
    " 'liters',\n",
    " 'loaf',\n",
    " 'loaves',\n",
    " 'log',\n",
    " 'logs',\n",
    " 'lump',\n",
    " 'mg',\n",
    " 'milliliter',\n",
    " 'minute',\n",
    " 'ml',\n",
    " 'neck',\n",
    " 'ounce',\n",
    " 'ounces',\n",
    " 'oval',\n",
    " 'oz',\n",
    " 'package',\n",
    " 'packaged',\n",
    " 'packages',\n",
    " 'packet',\n",
    " 'packets',\n",
    " 'peel',\n",
    " 'peels',\n",
    " 'piece',\n",
    " 'pieces',\n",
    " 'pinch',\n",
    " 'pinches',\n",
    " 'pint',\n",
    " 'pints',\n",
    " 'pitted',\n",
    " 'pkg',\n",
    " 'pocket',\n",
    " 'pod',\n",
    " 'pods',\n",
    " 'portions',\n",
    " 'pot',\n",
    " 'pouch',\n",
    " 'pouches',\n",
    " 'pound',\n",
    " 'pounds',\n",
    " 'quart',\n",
    " 'quarts',\n",
    " 'rack',\n",
    " 'racks',\n",
    " 'ring',\n",
    " 'rings',\n",
    " 'roll',\n",
    " 'rolls',\n",
    " 'round',\n",
    " 'scoop',\n",
    " 'scoops',\n",
    " 'serving',\n",
    " 'servings',\n",
    " 'set',\n",
    " 'sheet',\n",
    " 'sheets',\n",
    " 'shells',\n",
    " 'shot',\n",
    " 'shots',\n",
    " 'skewers',\n",
    " 'slab',\n",
    " 'slabs',\n",
    " 'sleeve',\n",
    " 'sleeves',\n",
    " 'slice',\n",
    " 'slices',\n",
    " 'spears',\n",
    " 'splash',\n",
    " 'splashes',\n",
    " 'spray',\n",
    " 'sprays',\n",
    " 'sprinkle',\n",
    " 'square',\n",
    " 'squares',\n",
    " 'squeeze',\n",
    " 'squeezes',\n",
    " 'squirts',\n",
    " 'stalk',\n",
    " 'stalks',\n",
    " 'star',\n",
    " 'stems',\n",
    " 'stewing',\n",
    " 'stick',\n",
    " 'sticks',\n",
    " 'store',\n",
    " 'strands',\n",
    " 'straw',\n",
    " 'strip',\n",
    " 'strips',\n",
    " 'tablespoon',\n",
    " 'tablespoons',\n",
    " 'tablet',\n",
    " 'tablets',\n",
    " 'teaspoon',\n",
    " 'teaspoons',\n",
    " 'tins',\n",
    " 'tray',\n",
    " 'trays',\n",
    " 'tub',\n",
    " 'tube',\n",
    " 'tubes',\n",
    " 'tubs',\n",
    " 'twist',\n",
    " 'twists',\n",
    " 'wedge',\n",
    " 'wedges',\n",
    " 'wheel',\n",
    " 'wheels',\n",
    " 'wrap',\n",
    " 'wraps',\n",
    " 'tbsp',\n",
    " 'tsp',\n",
    " 'l',\n",
    " 'g',\n",
    " 'tbsps',\n",
    " 'tsps',\n",
    " 'cm',\n",
    " 'tin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ingredients_with_notes = pd.read_csv('ingredients_PCA_with_notes.csv')\n",
    "df_ingredients_with_notes.drop(columns=['Unnamed: 0'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>match</th>\n",
       "      <th>order</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gochujang base</td>\n",
       "      <td>gochujang base</td>\n",
       "      <td>2</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ketchup</td>\n",
       "      <td>ketchup</td>\n",
       "      <td>1</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>maple syrup</td>\n",
       "      <td>maple syrup</td>\n",
       "      <td>2</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>soy sauce</td>\n",
       "      <td>soy sauce</td>\n",
       "      <td>2</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>seasoned rice wine vinegar</td>\n",
       "      <td>seasoned rice wine vinegar</td>\n",
       "      <td>4</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26173</th>\n",
       "      <td>902</td>\n",
       "      <td>banana</td>\n",
       "      <td>banana</td>\n",
       "      <td>1</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26174</th>\n",
       "      <td>902</td>\n",
       "      <td>almond milk</td>\n",
       "      <td>almond milk</td>\n",
       "      <td>2</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26175</th>\n",
       "      <td>902</td>\n",
       "      <td>packet frozen acai</td>\n",
       "      <td>za'atar</td>\n",
       "      <td>0</td>\n",
       "      <td>Not perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26176</th>\n",
       "      <td>903</td>\n",
       "      <td>banana</td>\n",
       "      <td>banana</td>\n",
       "      <td>1</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26177</th>\n",
       "      <td>903</td>\n",
       "      <td>almond milk</td>\n",
       "      <td>almond milk</td>\n",
       "      <td>2</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26178 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                 Ingredients                       match  order  \\\n",
       "0        1              gochujang base              gochujang base      2   \n",
       "1        1                     ketchup                     ketchup      1   \n",
       "2        1                 maple syrup                 maple syrup      2   \n",
       "3        1                   soy sauce                   soy sauce      2   \n",
       "4        1  seasoned rice wine vinegar  seasoned rice wine vinegar      4   \n",
       "...    ...                         ...                         ...    ...   \n",
       "26173  902                      banana                      banana      1   \n",
       "26174  902                 almond milk                 almond milk      2   \n",
       "26175  902          packet frozen acai                     za'atar      0   \n",
       "26176  903                      banana                      banana      1   \n",
       "26177  903                 almond milk                 almond milk      2   \n",
       "\n",
       "              note  \n",
       "0          Perfect  \n",
       "1          Perfect  \n",
       "2          Perfect  \n",
       "3          Perfect  \n",
       "4          Perfect  \n",
       "...            ...  \n",
       "26173      Perfect  \n",
       "26174      Perfect  \n",
       "26175  Not perfect  \n",
       "26176      Perfect  \n",
       "26177      Perfect  \n",
       "\n",
       "[26178 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ingredients_with_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tree.json') as json_file:\n",
    "    dict_tree = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strsimpy import Cosine\n",
    "from itertools import permutations\n",
    "\n",
    "cos = Cosine(1)\n",
    "\n",
    "def find(s, trees, order, steps):\n",
    "    max_order = s.split(' ')\n",
    "    candidates = []\n",
    "    \n",
    "    if order < len(s.split(' ')):\n",
    "        \n",
    "        for i in permutations(s.split(' '), order):\n",
    "            for tree in trees:\n",
    "                candidate = tree.get(' '.join(i))\n",
    "                if candidate is not None:\n",
    "                    steps.append((' '.join(i), order))\n",
    "                    candidates.append(candidate)\n",
    " \n",
    "        if not candidates:\n",
    "            \n",
    "            if any([not(tree.keys()) for tree in trees]):\n",
    "                \n",
    "                return steps[-1]\n",
    "            \n",
    "            max_cosine_score = float('-inf')\n",
    "            \n",
    "            for i in permutations(s.split(' '), order):\n",
    "                for tree in trees:\n",
    "                    candidates = tree.keys()\n",
    "                    for key in candidates:\n",
    "                        if 1 - cos.distance(' '.join(i), key) > max_cosine_score:\n",
    "                            max_cosine_score = 1 - cos.distance(s, key)\n",
    "                            best_key = key\n",
    "                steps.append((best_key, order - 1))\n",
    "            \n",
    "            return steps[-1]\n",
    "            \n",
    "        find(s, candidates, order+1, steps)\n",
    "        \n",
    "    else:\n",
    "        for tree in trees:\n",
    "            candidate = tree.get(s)\n",
    "            if candidate is not None:\n",
    "                steps.append((s, order))\n",
    "                \n",
    "        if not steps:\n",
    "            \n",
    "            max_cosine_score = float('-inf')\n",
    "            \n",
    "            for tree in trees:\n",
    "                candidates = tree.keys()\n",
    "                for key in candidates:\n",
    "                    if 1 - cos.distance(s, key) > max_cosine_score:\n",
    "                        max_cosine_score = 1 - cos.distance(s, key)\n",
    "                        best_key = key\n",
    "                            \n",
    "            steps.append((best_key, order - 1))\n",
    "            \n",
    "            return steps[-1]\n",
    "            \n",
    "    return steps[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def loose_eval(s, l):\n",
    "    for i in l:\n",
    "        if s in i or i in s:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2299it [03:14, 11.81it/s]\n"
     ]
    }
   ],
   "source": [
    "diff = []\n",
    "stat_result = []\n",
    "\n",
    "for row in tqdm(df_INQ_agged.itertuples()):\n",
    "    \n",
    "    additional = []\n",
    "    perfect_match_from_database = 0\n",
    "    perfect_match_from_dict = 0\n",
    "    perfect_match_from_database_not_in_dict = 0\n",
    "    loose_match_from_database = 0\n",
    "    loose_match_from_dict = 0\n",
    "    loose_match_from_dict_predict = 0\n",
    "    wrong_count = 0\n",
    "    \n",
    "    ID = row.ID\n",
    "    \n",
    "    ingredients = df_ingredients_with_notes[df_ingredients_with_notes['ID'] == ID]\n",
    "    \n",
    "    base_match = ingredients['Ingredients'].to_list()\n",
    "    \n",
    "    perfect_match = ingredients[ingredients['note'] == 'Perfect']['match'].to_list()\n",
    "    \n",
    "    not_agree_match = ingredients[ingredients['note'] == 'Not perfect']['match'].to_list()\n",
    "    \n",
    "    input_texts = row.INQs\n",
    "    \n",
    "    for text in input_texts:\n",
    "        \n",
    "        result = test_regex.match(text)\n",
    "    \n",
    "        if result is not None and result.groups()[-2] in units:\n",
    "            \n",
    "            if result.groups()[-1] != '':\n",
    "\n",
    "                result = result.groups()[-1]\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                result = text\n",
    "                \n",
    "        else:\n",
    "                \n",
    "            result = text\n",
    "\n",
    "        chunking = nltk.RegexpParser(gram)\n",
    "        sent_token = nltk.word_tokenize(result)\n",
    "        tagging = nltk.pos_tag(sent_token)\n",
    "        tree = chunking.parse(tagging)\n",
    "        \n",
    "        result = []\n",
    "\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'NP':\n",
    "                result.extend(subtree.leaves())\n",
    "                \n",
    "        final = \" \".join([x[0] for x in result])\n",
    "        \n",
    "        if final is not None:\n",
    "            if final in perfect_match: # perfect match\n",
    "                perfect_match_from_database += 1\n",
    "            elif find(final, [dict_tree], 1, []):\n",
    "                if find(final, [dict_tree], 1, [])[0] == final:\n",
    "                    perfect_match_from_dict += 1\n",
    "                elif 1 - cos.distance(final, find(final, [dict_tree], 1, [])[0]) > 0.9:\n",
    "                    loose_match_from_dict += 1\n",
    "                else:\n",
    "                    diff.append(f'{text}, {final}, {ID} \\n')\n",
    "                    wrong_count += 1\n",
    "            elif final in base_match:\n",
    "                perfect_match_from_database_not_in_dict += 1\n",
    "                additional.append(final)\n",
    "            elif final in loose_eval(final, base_match): # ingredients not 100 found in dict so default to base\n",
    "                loose_match_from_database += 1\n",
    "            elif final in loose_eval(final, not_agree_match):\n",
    "                loose_match_from_dict_predict += 1\n",
    "            elif find(final, [dict_tree], 1, []):\n",
    "                if 1 - cos.distance(final, find(final, [dict_tree], 1, [])[0]) > 0.9:\n",
    "                    loose_match_from_dict += 1\n",
    "                else:\n",
    "                    diff.append(f'{text}, {final}, {ID} \\n')\n",
    "                    wrong_count += 1\n",
    "            else:\n",
    "                diff.append(f'{text}, {final}, {ID} \\n')\n",
    "                wrong_count += 1\n",
    "            # extract.append(final)\n",
    "            \n",
    "    stat_result.append({\n",
    "        'additional': additional,\n",
    "        'perfect_match_from_database' : perfect_match_from_database,\n",
    "        'perfect_match_from_dict': perfect_match_from_dict,\n",
    "        'perfect_match_from_database_not_in_dict': perfect_match_from_database_not_in_dict,\n",
    "        'loose_match_from_database': loose_match_from_database,\n",
    "        'loose_match_from_dict': loose_match_from_dict,\n",
    "        'loose_match_from_dict_predict': loose_match_from_dict_predict,\n",
    "        'wrong_count': wrong_count,\n",
    "    })\n",
    "        \n",
    "file = open('compare.txt', 'w')\n",
    "\n",
    "file.writelines(diff)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional': [],\n",
       " 'perfect_match_from_database': 15,\n",
       " 'perfect_match_from_dict': 3,\n",
       " 'perfect_match_from_database_not_in_dict': 0,\n",
       " 'loose_match_from_database': 0,\n",
       " 'loose_match_from_dict': 2,\n",
       " 'loose_match_from_dict_predict': 0,\n",
       " 'wrong_count': 3}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = []\n",
    "\n",
    "for i in stat_result:\n",
    "    total = sum(list(i.values())[1:])\n",
    "    strict_count = i['perfect_match_from_database'] + i['perfect_match_from_dict'] + i['perfect_match_from_database_not_in_dict']\n",
    "    loose_count = total - i['wrong_count']\n",
    "    strict_acc = strict_count / total\n",
    "    loose_acc = loose_count / total\n",
    "    analysis.append((strict_acc, loose_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_accs = [x[0] for x in analysis]\n",
    "loose_accs = [x[1] for x in analysis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict mean:  0.7100545710010074\n",
      "Strict std:  0.16769228166825462\n",
      "Strict var:  0.028120701331105245\n",
      "Loose mean:  0.7726803903229852\n",
      "Loose std:  0.15111956608105545\n",
      "Loose var:  0.022837123252526483\n"
     ]
    }
   ],
   "source": [
    "print('Strict mean: ', np.mean(strict_accs))\n",
    "print('Strict std: ', np.std(strict_accs))\n",
    "print('Strict var: ', np.var(strict_accs))\n",
    "print('Loose mean: ', np.mean(loose_accs))\n",
    "print('Loose std: ', np.std(loose_accs))\n",
    "print('Loose var: ', np.var(loose_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_INQ_agged.loc[0]['INQs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
