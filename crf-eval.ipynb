{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('([0-9]*\\.?[0-9]*) ?(\\( ([0-9]*) ([a-z]*) \\))? ([a-z]*) (.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = p.match('0.5 ( 1 ounce ) package dry ranch - style dressing mix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: 0.5\n",
      "Group 1: ( 1 ounce )\n",
      "Group 2: 1\n",
      "Group 3: ounce\n",
      "Group 4: package\n",
      "Group 5: dry ranch - style dressing mix\n"
     ]
    }
   ],
   "source": [
    "for idx, match in enumerate(m.groups()):\n",
    "    print(f'Group {idx}: {match}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('crf_big.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2featuresmod(sent, i):\n",
    "    word = sent[i].text\n",
    "    postag = sent[i].tag_\n",
    "    \n",
    "    # data structure consisting of a feature name and value for the token\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(), # lower case variant of the token\n",
    "        'word[-3:]': word[-3:], #suffix of 3 characters\n",
    "        'word[-2:]': word[-2:], #suffix of 2 characters\n",
    "        'word.isupper()': word.isupper(), # initial captial\n",
    "        'word.istitle()': word.istitle(), # all words ini caps\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2], #first two characters of the PoS Tag\n",
    "    }\n",
    "    if i > 0:\n",
    "        # adding features for the word based on the previous word\n",
    "        word1 = sent[i-1].text # previous word\n",
    "        postag1 = sent[i-1].tag_\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True # Beginning of sentence as a feature\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        # adding features for the word based on the next word\n",
    "        word1 = sent[i+1].text # next word\n",
    "        postag1 = sent[i+1].tag_\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True # end of sentence as a feature\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2featuresmod(sent):\n",
    "    return [word2featuresmod(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labelsmod(sent):\n",
    "    return [x.NER_tags for x in sent]\n",
    "\n",
    "def sent2tokensmod(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix O\n",
      "the O\n",
      "mustard O\n",
      "mayo B-ING\n",
      "through O\n",
      "the O\n",
      "cooked O\n",
      "potatoes B-ING\n",
      "with O\n",
      "the O\n",
      "spring B-ING\n",
      "onions I-ING\n",
      ", O\n",
      "apple B-ING\n",
      "and I-ING\n",
      "celery I-ING\n"
     ]
    }
   ],
   "source": [
    "text = \"mix the mustard mayo through the cooked potatoes with the spring onions, apple and celery\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "tokens = [token for token in doc]\n",
    "\n",
    "prep = sent2featuresmod(tokens)\n",
    "# prep\n",
    "\n",
    "predict = model.predict([prep])\n",
    "\n",
    "for idx, token in enumerate(tokens):\n",
    "    print(token, predict[0][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
